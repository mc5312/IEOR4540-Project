{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyPnGtXiHlv0jPlfeJ35iQan"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torch import nn, optim\n","\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","\n","from datetime import datetime\n","from tqdm import tqdm\n","import time\n","import numpy as np\n","\n","# # Mount Google Drive if needed\n","# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"nRGad0z12uFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== Helper Functions ==========\n","\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","def convert_to_superclass(targets):\n","    # For CIFAR100, convert 100 classes to 20 superclasses\n","    superclass_labels = np.array([\n","         4,  1, 14,  8,  0,  6,  7,  7, 18,  3,\n","         3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n","         6, 11,  5, 10,  7,  6, 13, 15,  3, 15,\n","         0, 11,  1, 10, 12, 14, 16,  9, 11,  5,\n","         5, 19,  8,  8, 15, 13, 14, 17, 18, 10,\n","        16,  4, 17,  4,  2,  0, 17,  4, 18, 17,\n","        10,  3,  2, 12, 12, 16, 12,  1,  9, 19,\n","         2, 10,  0,  1, 16, 12,  9, 13, 15, 13,\n","        16, 19,  2,  4,  6, 19,  5,  5,  8, 19,\n","        18,  1,  2, 15,  6,  0, 17,  8, 14, 13\n","        ])\n","    return superclass_labels[targets]\n","\n","# Device configuration\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"D4ecOlMh9yCK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gyt7E1Gg2nrd"},"outputs":[],"source":["# ========== Main ViT Logic ==========\n","# This code is modified from regular ViT implementation: https://github.com/lucidrains/vit-pytorch\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout = 0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Attention(nn.Module):\n","    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n","        super().__init__()\n","        inner_dim = dim_head *  heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","\n","        self.norm = nn.LayerNorm(dim)\n","\n","        self.attend = nn.Softmax(dim = -1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","\n","        qkv = self.to_qkv(x).chunk(3, dim = -1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n","\n","        attn = self.attend(dots)\n","        attn = self.dropout(attn)\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","class PerformerAttention(nn.Module):\n","    # This PerformerAttention is modified from regular Attention.\n","    # Different attention kernels are available in kernel(self, x).\n","\n","    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0., model_type='performer_relu',\n","            explu_exp_weight=None, explu_relu_weight=None\n","            ):\n","        super().__init__()\n","        inner_dim = dim_head *  heads\n","        project_out = not (heads == 1 and dim_head == dim)\n","\n","        self.heads = heads\n","        self.scale = dim_head ** -0.5\n","        self.model_type = model_type\n","\n","        self.norm = nn.LayerNorm(dim)\n","\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        ) if project_out else nn.Identity()\n","\n","        self.explu_exp_weight, self.explu_relu_weight = explu_exp_weight, explu_relu_weight\n","\n","        self.kernel = None\n","        if self.model_type == 'performer_relu':\n","            self.kernel = self.kernel_relu\n","        elif self.model_type == 'performer_exp':\n","            self.kernel = self.kernel_exp\n","        elif self.model_type == 'performer_explu':\n","            self.kernel = self.kernel_explu\n","\n","    def kernel_relu(self, x):\n","        return torch.nn.functional.relu(x)\n","\n","    def kernel_exp(self, x):\n","        return torch.exp(x)\n","\n","    def kernel_explu(self, x):\n","        return self.explu_exp_weight * torch.exp(x) + self.explu_relu_weight * torch.nn.functional.relu(x)\n","\n","    def forward(self, x):\n","        x = self.norm(x)\n","\n","        qkv = self.to_qkv(x).chunk(3, dim = -1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","\n","        q = self.kernel(q)\n","        k = self.kernel(k)\n","        out = torch.matmul(k.transpose(-1, -2), v)\n","        out = torch.matmul(q, out) * self.scale\n","\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","\n","class Transformer(nn.Module):\n","    # The Transformer logic is modified to choose between regular attention and perfomer attention based on model_type\n","\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0., model_type='regular_transformer',\n","            explu_exp_weight=None, explu_relu_weight=None\n","            ):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.layers = nn.ModuleList([])\n","\n","        if model_type == 'regular_transformer':\n","            # Regular Attention\n","            for _ in range(depth):\n","                self.layers.append(nn.ModuleList([\n","                    Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n","                    FeedForward(dim, mlp_dim, dropout = dropout)\n","                ]))\n","        else:\n","            # Performer Attention\n","            for _ in range(depth):\n","                self.layers.append(nn.ModuleList([\n","                    PerformerAttention(\n","                        dim, heads = heads, dim_head = dim_head, dropout = dropout, model_type=model_type,\n","                        explu_exp_weight=explu_exp_weight, explu_relu_weight=explu_relu_weight),\n","                    FeedForward(dim, mlp_dim, dropout = dropout)\n","                ]))\n","\n","    def forward(self, x):\n","        for attn, ff in self.layers:\n","            x = attn(x) + x\n","            x = ff(x) + x\n","\n","        return self.norm(x)\n","\n","\n","class ViT(nn.Module):\n","    def __init__(\n","            self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls',\n","            channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.,\n","            model_type='regurlar_transformer', explu_exp_weight_init=-0.2, explu_relu_weight_init=0.8):\n","        super().__init__()\n","        image_height, image_width = pair(image_size)\n","        patch_height, patch_width = pair(patch_size)\n","\n","        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n","\n","        num_patches = (image_height // patch_height) * (image_width // patch_width)\n","        patch_dim = channels * patch_height * patch_width\n","        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n","\n","        self.to_patch_embedding = nn.Sequential(\n","            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n","            nn.LayerNorm(patch_dim),\n","            nn.Linear(patch_dim, dim),\n","            nn.LayerNorm(dim),\n","        )\n","\n","        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n","        self.dropout = nn.Dropout(emb_dropout)\n","\n","        self.explu_exp_weight = nn.Parameter(torch.tensor(explu_exp_weight_init)) if model_type == 'performer_explu' else None\n","        self.explu_relu_weight = nn.Parameter(torch.tensor(explu_relu_weight_init)) if model_type == 'performer_explu' else None\n","\n","        self.transformer = Transformer(\n","            dim, depth, heads, dim_head, mlp_dim, dropout, model_type,\n","            explu_exp_weight=self.explu_exp_weight, explu_relu_weight=self.explu_relu_weight\n","            )\n","\n","        self.pool = pool\n","        self.to_latent = nn.Identity()\n","\n","        self.mlp_head = nn.Linear(dim, num_classes)\n","\n","    def forward(self, img):\n","        x = self.to_patch_embedding(img)\n","        b, n, _ = x.shape\n","\n","        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","        x += self.pos_embedding[:, :(n + 1)]\n","        x = self.dropout(x)\n","\n","        x = self.transformer(x)\n","\n","        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n","\n","        x = self.to_latent(x)\n","        return self.mlp_head(x)"]},{"cell_type":"code","source":["# ========== Train and Test ==========\n","\n","def train_epoch(model, loader, optimizer, criterion, device):\n","    model.train()\n","    pbar = tqdm(loader)\n","    total_loss = 0\n","    train_count = 0\n","    correct = 0\n","\n","    for images, labels in pbar:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        total_loss += loss.item()\n","\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Accuracy\n","        _, preds = torch.max(outputs, 1)\n","        correct += (preds == labels).sum().item()\n","        train_count += 1\n","        pbar.set_description(f\"Loss : {total_loss/train_count:.4f}\")\n","\n","    avg_loss = total_loss / len(loader)\n","    accuracy = correct / len(loader.dataset)\n","    return avg_loss, accuracy\n","\n","def test_epoch(model, loader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","\n","            # Accuracy\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","\n","    avg_loss = total_loss / len(loader)\n","    accuracy = correct / len(loader.dataset)\n","    return avg_loss, accuracy\n"],"metadata":{"id":"b2JFLeTZ3LM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== Experiment Logic ==========\n","\n","def run_experitment(model, train_loader, test_loader, optimizer, criterion, device, run_name, epochs_to_run, checkpoint):\n","\n","    epoch_stat, current_epoch = {}, 0\n","    if checkpoint is not None:\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        epoch_stat = checkpoint['stat']\n","        current_epoch = list(epoch_stat.keys())[-1]\n","        print(f\"Loaded checkpoint at epoch {current_epoch}\")\n","\n","    # Training process\n","    for epoch in range(current_epoch + 1, current_epoch + epochs_to_run + 1):\n","        print(f\"Epoch {epoch}/{current_epoch + epochs_to_run}\")\n","\n","        # Training\n","        train_start_time = time.time()\n","        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n","        if device == 'cuda': torch.cuda.synchronize()\n","        train_time = time.time() - train_start_time\n","\n","        # Testing\n","        test_start_time = time.time()\n","        test_loss, test_acc = test_epoch(model, test_loader, criterion, device)\n","        if device == 'cuda': torch.cuda.synchronize()\n","        test_time = time.time() - test_start_time\n","\n","        # Display\n","        print(f\"Train Time: {train_time:2f}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n","        print(f\"Test Time: {test_time:2f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n","        print()\n","\n","        # Update epoch_stat\n","        epoch_stat[epoch] = {\n","            'train_time': train_time, 'train_loss': train_loss, 'train_acc': train_acc,\n","            'test_time': test_time, 'test_loss': test_loss, 'test_acc': test_acc\n","        }\n","\n","        # Write to checkpoint\n","        if (epoch % 5 == 0) or (epoch == current_epoch + epochs_to_run):\n","            torch.save({\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'stat': epoch_stat,\n","            }, \"./checkpoint_\" + run_name)\n"],"metadata":{"id":"ddE_p8SI3LFf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== Experiment Parameters ==========\n","\n","epochs_to_run = 100\n","\n","model_type = 'performer_explu'\n","# Possible values: 'regular_transformer', 'performer_relu', 'performer_exp', 'performer_explu'\n","\n","dataset_name = 'MNIST'\n","# Possible values: 'MNIST', 'CIFAR10', 'CIFAR100'\n","\n","run_name = \"{}_{}\".format(model_type, dataset_name)\n","\n","checkpoint = None\n","# # Load checkpoint if needed\n","# checkpoint = torch.load(\"./checkpoint_\" + run_name, weights_only=True)"],"metadata":{"id":"eidUbuk6M4PN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== Load Dataset, based on Experiment Param ==========\n","\n","train_dataset, test_dataset, train_loader, test_loader = None, None, None, None\n","\n","if dataset_name == 'MNIST':\n","    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n","    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n","    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","elif dataset_name == 'CIFAR10':\n","    train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n","    test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n","    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","elif dataset_name == 'CIFAR100':\n","    train_dataset = datasets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n","    test_dataset = datasets.CIFAR100(root='./data', train=False, transform=transform, download=True)\n","    train_dataset.targets = convert_to_superclass(train_dataset.targets)\n","    test_dataset.targets = convert_to_superclass(test_dataset.targets)\n","    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"],"metadata":{"id":"GYuM7pPQ9eFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== Load Model, based on Experiment Param ==========\n","\n","torch.manual_seed(0)\n","model = None\n","\n","if dataset_name in ['MNIST']:\n","    model = ViT(\n","        image_size=28, channels=1, num_classes=10,\n","        patch_size=4, dim=8, dim_head=8,\n","        depth=6, heads=8, mlp_dim=256,\n","        dropout=0.1, emb_dropout=0.1, model_type=model_type\n","    ).to(device)\n","elif dataset_name in ['CIFAR10']:\n","    model = ViT(\n","        image_size=32, channels=3, num_classes=10,\n","        patch_size=4, dim=32, dim_head=16,\n","        depth=6, heads=16, mlp_dim=256,\n","        dropout=0.1, emb_dropout=0.1, model_type=model_type\n","    ).to(device)\n","elif dataset_name in ['CIFAR100']:\n","    model = ViT(\n","        image_size=32, channels=3, num_classes=20,\n","        patch_size=4, dim=32, dim_head=16,\n","        depth=6, heads=32, mlp_dim=256,\n","        dropout=0.1, emb_dropout=0.1, model_type=model_type\n","    ).to(device)\n","\n","# Load Optimizer and Loss Function\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)"],"metadata":{"id":"zgcIli2E3LIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== Run experiment on selected model and dataset ==========\n","# Experiment results are also exported to checkpoints.\n","\n","run_experitment(model, train_loader, test_loader, optimizer, criterion, device, run_name, epochs_to_run, checkpoint)"],"metadata":{"id":"rwzh_tESXKxC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The Following cell is for measuring Inference Time."],"metadata":{"id":"IP9HDPF8l8SL"}},{"cell_type":"code","source":["# ========== Test Inference Time ==========\n","\n","dataset_name = 'CIFAR100'\n","# Possible values: 'MNIST', 'CIFAR10', 'CIFAR100'\n","\n","test_input, test_model, inference_time = None, {}, {}\n","model_type_ls = ['regular_transformer', 'performer_relu', 'performer_exp', 'performer_explu']\n","\n","# Create models and dummy image\n","if dataset_name in ['MNIST']:\n","    for model_type in model_type_ls:\n","        test_model[model_type] = ViT(\n","            image_size=28, channels=1, num_classes=10,\n","            patch_size=4, dim=8, dim_head=8,\n","            depth=6, heads=8, mlp_dim=256,\n","            dropout=0.1, emb_dropout=0.1, model_type=model_type\n","        ).to('cpu')\n","        inference_time[model_type] = []\n","    test_input = torch.randn(1, 1, 28, 28).to('cpu')\n","elif dataset_name in ['CIFAR10']:\n","    for model_type in model_type_ls:\n","        test_model[model_type] = ViT(\n","            image_size=32, channels=3, num_classes=10,\n","            patch_size=4, dim=32, dim_head=16,\n","            depth=6, heads=16, mlp_dim=256,\n","            dropout=0.1, emb_dropout=0.1, model_type=model_type\n","        ).to('cpu')\n","        inference_time[model_type] = []\n","    test_input = torch.randn(1, 3, 32, 32).to('cpu')\n","elif dataset_name in ['CIFAR100']:\n","    for model_type in model_type_ls:\n","        test_model[model_type] = ViT(\n","            image_size=32, channels=3, num_classes=20,\n","            patch_size=4, dim=32, dim_head=16,\n","            depth=6, heads=32, mlp_dim=256,\n","            dropout=0.1, emb_dropout=0.1, model_type=model_type\n","        ).to('cpu')\n","        inference_time[model_type] = []\n","    test_input = torch.randn(1, 3, 32, 32).to('cpu')\n","\n","# Warm-up\n","for i in range(100):\n","    this_model_type = model_type_ls[i % len(model_type_ls)]\n","    _ = test_model[this_model_type](test_input)\n","\n","# Measure Inference Time\n","num_iterations = 40000\n","for i in range(num_iterations):\n","    this_model_type = model_type_ls[i % len(model_type_ls)]\n","    start_time = time.time()\n","    _ = test_model[this_model_type](test_input)\n","    end_time = time.time()\n","    inference_time[this_model_type] += [end_time - start_time]\n","\n","# Display Result\n","for model_type in model_type_ls:\n","    print(f\"{model_type}: {np.mean(inference_time[model_type]):.6f} seconds\")"],"metadata":{"id":"3BAXPLgCtjxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The following cells are for checking number of parameters and parameter values."],"metadata":{"id":"-XrxoQOhl1Rx"}},{"cell_type":"code","source":["# ========== Show number of Parameters ==========\n","\n","model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])\n","print(params)"],"metadata":{"id":"a8Hv72aIctm2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ========== Check Learnable Param value for Kernel Feature ==========\n","\n","if 'performer_explu' in model_type:\n","    for name, param in model.named_parameters():\n","        if any(param in name for param in ['explu_exp_weight', 'explu_relu_weight']):\n","            print(name, param.data)"],"metadata":{"id":"cVxqi-AIodHK"},"execution_count":null,"outputs":[]}]}